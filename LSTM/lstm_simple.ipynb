{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lstm_cell_forward(input_current, hidden_state_previous, cell_state_previous, \n",
        "                      weight_ih_f, weight_hh_f, bias_f,\n",
        "                      weight_ih_i, weight_hh_i, bias_i,\n",
        "                      weight_ih_c, weight_hh_c, bias_c,\n",
        "                      weight_ih_o, weight_hh_o, bias_o):\n",
        "    \"\"\"\n",
        "    Forward pass của LSTM cell - Version đơn giản nhất\n",
        "    \n",
        "    Args:\n",
        "        input_current: (batch_size, input_size)\n",
        "        hidden_state_previous: (batch_size, hidden_size)\n",
        "        cell_state_previous: (batch_size, hidden_size)\n",
        "        weight_ih_f, weight_hh_f, bias_f: Parameters cho Forget Gate\n",
        "        weight_ih_i, weight_hh_i, bias_i: Parameters cho Input Gate\n",
        "        weight_ih_c, weight_hh_c, bias_c: Parameters cho Candidate Gate\n",
        "        weight_ih_o, weight_hh_o, bias_o: Parameters cho Output Gate\n",
        "    \n",
        "    Returns:\n",
        "        hidden_state_new: (batch_size, hidden_size)\n",
        "        cell_state_new: (batch_size, hidden_size)\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. FORGET GATE: Quyết định quên thông tin nào từ cell state cũ\n",
        "    # forget_gate = sigmoid(W_f * x + U_f * h_prev + b_f)\n",
        "    forget_gate = torch.sigmoid(\n",
        "        torch.mm(input_current, weight_ih_f.t()) + \n",
        "        torch.mm(hidden_state_previous, weight_hh_f.t()) + \n",
        "        bias_f\n",
        "    )\n",
        "    \n",
        "    # 2. INPUT GATE: Quyết định lưu thông tin mới nào\n",
        "    # input_gate = sigmoid(W_i * x + U_i * h_prev + b_i)\n",
        "    input_gate = torch.sigmoid(\n",
        "        torch.mm(input_current, weight_ih_i.t()) + \n",
        "        torch.mm(hidden_state_previous, weight_hh_i.t()) + \n",
        "        bias_i\n",
        "    )\n",
        "    \n",
        "    # 3. CANDIDATE GATE: Tạo giá trị candidate cho cell state mới\n",
        "    # candidate_gate = tanh(W_c * x + U_c * h_prev + b_c)\n",
        "    candidate_gate = torch.tanh(\n",
        "        torch.mm(input_current, weight_ih_c.t()) + \n",
        "        torch.mm(hidden_state_previous, weight_hh_c.t()) + \n",
        "        bias_c\n",
        "    )\n",
        "    \n",
        "    # 4. OUTPUT GATE: Quyết định output phần nào của cell state\n",
        "    # output_gate = sigmoid(W_o * x + U_o * h_prev + b_o)\n",
        "    output_gate = torch.sigmoid(\n",
        "        torch.mm(input_current, weight_ih_o.t()) + \n",
        "        torch.mm(hidden_state_previous, weight_hh_o.t()) + \n",
        "        bias_o\n",
        "    )\n",
        "    \n",
        "    # 5. CẬP NHẬT CELL STATE\n",
        "    # cell_state_new = forget_gate * cell_state_prev + input_gate * candidate_gate\n",
        "    cell_state_new = forget_gate * cell_state_previous + input_gate * candidate_gate\n",
        "    \n",
        "    # 6. CẬP NHẬT HIDDEN STATE\n",
        "    # hidden_state_new = output_gate * tanh(cell_state_new)\n",
        "    hidden_state_new = output_gate * torch.tanh(cell_state_new)\n",
        "    \n",
        "    return hidden_state_new, cell_state_new\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_lstm_parameters(input_size, hidden_size):\n",
        "    \"\"\"\n",
        "    Khởi tạo parameters cho LSTM - Đơn giản nhất\n",
        "    \"\"\"\n",
        "    # Forget Gate parameters\n",
        "    weight_ih_f = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "    weight_hh_f = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "    bias_f = nn.Parameter(torch.ones(hidden_size))  # Bias = 1 để giúp gradient flow\n",
        "    \n",
        "    # Input Gate parameters\n",
        "    weight_ih_i = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "    weight_hh_i = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "    bias_i = nn.Parameter(torch.zeros(hidden_size))\n",
        "    \n",
        "    # Candidate Gate parameters\n",
        "    weight_ih_c = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "    weight_hh_c = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "    bias_c = nn.Parameter(torch.zeros(hidden_size))\n",
        "    \n",
        "    # Output Gate parameters\n",
        "    weight_ih_o = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "    weight_hh_o = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "    bias_o = nn.Parameter(torch.zeros(hidden_size))\n",
        "    \n",
        "    return {\n",
        "        'weight_ih_f': weight_ih_f, 'weight_hh_f': weight_hh_f, 'bias_f': bias_f,\n",
        "        'weight_ih_i': weight_ih_i, 'weight_hh_i': weight_hh_i, 'bias_i': bias_i,\n",
        "        'weight_ih_c': weight_ih_c, 'weight_hh_c': weight_hh_c, 'bias_c': bias_c,\n",
        "        'weight_ih_o': weight_ih_o, 'weight_hh_o': weight_hh_o, 'bias_o': bias_o\n",
        "    }\n",
        "\n",
        "def lstm_forward(input_sequence, params, batch_first=True):\n",
        "    \"\"\"\n",
        "    Forward pass qua LSTM layer cho sequence\n",
        "    \n",
        "    LƯU Ý: Cùng một bộ weights trong params được dùng cho TẤT CẢ các time steps\n",
        "    Đây là weight sharing - đặc điểm của Recurrent Networks\n",
        "    \n",
        "    Args:\n",
        "        input_sequence: (batch_size, seq_len, input_size) nếu batch_first=True\n",
        "                       (seq_len, batch_size, input_size) nếu batch_first=False\n",
        "        params: Dictionary chứa tất cả parameters (được share qua các time steps)\n",
        "        batch_first: True nếu input là (batch, seq, features)\n",
        "    \n",
        "    Returns:\n",
        "        output: (batch_size, seq_len, hidden_size) nếu batch_first=True\n",
        "                (seq_len, batch_size, hidden_size) nếu batch_first=False\n",
        "        final_hidden_state: (batch_size, hidden_size)\n",
        "        final_cell_state: (batch_size, hidden_size)\n",
        "    \"\"\"\n",
        "    if batch_first:\n",
        "        batch_size, seq_len, input_size = input_sequence.shape\n",
        "    else:\n",
        "        seq_len, batch_size, input_size = input_sequence.shape\n",
        "    \n",
        "    hidden_size = params['weight_ih_f'].shape[0]\n",
        "    \n",
        "    # Khởi tạo hidden và cell states\n",
        "    h = torch.zeros(batch_size, hidden_size, device=input_sequence.device, dtype=input_sequence.dtype)\n",
        "    c = torch.zeros(batch_size, hidden_size, device=input_sequence.device, dtype=input_sequence.dtype)\n",
        "    \n",
        "    outputs = []\n",
        "    \n",
        "    # Xử lý từng time step - DÙNG CÙNG BỘ WEIGHTS\n",
        "    for t in range(seq_len):\n",
        "        # Lấy input tại time step t\n",
        "        if batch_first:\n",
        "            x_t = input_sequence[:, t, :]  # (batch_size, input_size)\n",
        "        else:\n",
        "            x_t = input_sequence[t]  # (batch_size, input_size)\n",
        "        \n",
        "        # Forward qua LSTM cell - DÙNG CÙNG BỘ WEIGHTS cho mọi time step\n",
        "        h, c = lstm_cell_forward(\n",
        "            x_t, h, c,\n",
        "            params['weight_ih_f'], params['weight_hh_f'], params['bias_f'],\n",
        "            params['weight_ih_i'], params['weight_hh_i'], params['bias_i'],\n",
        "            params['weight_ih_c'], params['weight_hh_c'], params['bias_c'],\n",
        "            params['weight_ih_o'], params['weight_hh_o'], params['bias_o']\n",
        "        )\n",
        "        \n",
        "        # Lưu output\n",
        "        outputs.append(h)\n",
        "    \n",
        "    # Stack outputs\n",
        "    if batch_first:\n",
        "        output = torch.stack(outputs, dim=1)  # (batch_size, seq_len, hidden_size)\n",
        "    else:\n",
        "        output = torch.stack(outputs, dim=0)  # (seq_len, batch_size, hidden_size)\n",
        "    \n",
        "    return output, h, c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Demo Weight Sharing qua các Time Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Input sequence shape: torch.Size([1, 5, 2])\n",
            "Number of time steps: 5\n",
            "\n",
            "Weights được tạo 1 lần và dùng lại cho 5 time steps:\n",
            "\n",
            "ID của weight_ih_f: 1604014177920\n",
            "Time step 0: Input shape torch.Size([1, 2]), Hidden shape torch.Size([1, 3]), Weight ID: 1604014177920 (same: True)\n",
            "Time step 1: Input shape torch.Size([1, 2]), Hidden shape torch.Size([1, 3]), Weight ID: 1604014177920 (same: True)\n",
            "Time step 2: Input shape torch.Size([1, 2]), Hidden shape torch.Size([1, 3]), Weight ID: 1604014177920 (same: True)\n",
            "Time step 3: Input shape torch.Size([1, 2]), Hidden shape torch.Size([1, 3]), Weight ID: 1604014177920 (same: True)\n",
            "Time step 4: Input shape torch.Size([1, 2]), Hidden shape torch.Size([1, 3]), Weight ID: 1604014177920 (same: True)\n"
          ]
        }
      ],
      "source": [
        "# Demo: Cùng một bộ weights được dùng cho TẤT CẢ các time steps\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "batch_size = 1\n",
        "seq_len = 5\n",
        "\n",
        "# Khởi tạo parameters (CHỈ TẠO 1 LẦN)\n",
        "params = init_lstm_parameters(input_size, hidden_size)\n",
        "\n",
        "# Tạo input sequence\n",
        "input_sequence = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "# Khởi tạo states\n",
        "h = torch.zeros(batch_size, hidden_size)\n",
        "c = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "\n",
        "print(f\"\\nInput sequence shape: {input_sequence.shape}\")\n",
        "print(f\"Number of time steps: {seq_len}\")\n",
        "print(f\"\\nWeights được tạo 1 lần và dùng lại cho {seq_len} time steps:\")\n",
        "\n",
        "# Lưu id của weights để chứng minh cùng một object\n",
        "weight_id = id(params['weight_ih_f'])\n",
        "print(f\"\\nID của weight_ih_f: {weight_id}\")\n",
        "\n",
        "# Xử lý từng time step\n",
        "for t in range(seq_len):\n",
        "    x_t = input_sequence[:, t, :]\n",
        "    \n",
        "    # Forward qua LSTM cell - DÙNG CÙNG BỘ WEIGHTS\n",
        "    h, c = lstm_cell_forward(\n",
        "        x_t, h, c,\n",
        "        params['weight_ih_f'], params['weight_hh_f'], params['bias_f'],\n",
        "        params['weight_ih_i'], params['weight_hh_i'], params['bias_i'],\n",
        "        params['weight_ih_c'], params['weight_hh_c'], params['bias_c'],\n",
        "        params['weight_ih_o'], params['weight_hh_o'], params['bias_o']\n",
        "    )\n",
        "    \n",
        "    # Kiểm tra xem có cùng object không\n",
        "    current_weight_id = id(params['weight_ih_f'])\n",
        "    print(f\"Time step {t}: Input shape {x_t.shape}, Hidden shape {h.shape}, Weight ID: {current_weight_id} (same: {current_weight_id == weight_id})\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test LSTM Cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Initial hidden state shape: torch.Size([2, 3])\n",
            "Initial cell state shape: torch.Size([2, 3])\n",
            "\n",
            "After forward pass:\n",
            "New hidden state shape: torch.Size([2, 3])\n",
            "New cell state shape: torch.Size([2, 3])\n",
            "\n",
            "New hidden state:\n",
            "tensor([[ 4.4023e-02,  1.1454e-01, -2.6374e-03],\n",
            "        [-2.6462e-02,  2.8649e-01, -2.7646e-04]], grad_fn=<MulBackward0>)\n",
            "\n",
            "New cell state:\n",
            "tensor([[ 0.1464,  0.1384, -0.0578],\n",
            "        [-0.3858,  0.3016, -0.1774]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input_size = 4\n",
        "hidden_size = 3\n",
        "batch_size = 2\n",
        "\n",
        "# Khởi tạo parameters\n",
        "params = init_lstm_parameters(input_size, hidden_size)\n",
        "\n",
        "# Tạo input và initial states\n",
        "input_current = torch.randn(batch_size, input_size)\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "print(\"Input shape:\", input_current.shape)\n",
        "print(\"Initial hidden state shape:\", h_prev.shape)\n",
        "print(\"Initial cell state shape:\", c_prev.shape)\n",
        "\n",
        "# Forward pass\n",
        "h_new, c_new = lstm_cell_forward(\n",
        "    input_current, h_prev, c_prev,\n",
        "    params['weight_ih_f'], params['weight_hh_f'], params['bias_f'],\n",
        "    params['weight_ih_i'], params['weight_hh_i'], params['bias_i'],\n",
        "    params['weight_ih_c'], params['weight_hh_c'], params['bias_c'],\n",
        "    params['weight_ih_o'], params['weight_hh_o'], params['bias_o']\n",
        ")\n",
        "\n",
        "print(\"\\nAfter forward pass:\")\n",
        "print(\"New hidden state shape:\", h_new.shape)\n",
        "print(\"New cell state shape:\", c_new.shape)\n",
        "print(\"\\nNew hidden state:\")\n",
        "print(h_new)\n",
        "print(\"\\nNew cell state:\")\n",
        "print(c_new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 5, 4])\n",
            "\n",
            "Output shape: torch.Size([2, 5, 3])\n",
            "Final hidden state shape: torch.Size([2, 3])\n",
            "Final cell state shape: torch.Size([2, 3])\n",
            "\n",
            "Output:\n",
            "tensor([[[-0.0326, -0.0079, -0.4383],\n",
            "         [-0.1450,  0.6577,  0.3170],\n",
            "         [-0.0528,  0.0357,  0.0065],\n",
            "         [-0.0656,  0.3367,  0.3931],\n",
            "         [-0.2881,  0.0119,  0.0511]],\n",
            "\n",
            "        [[ 0.1387, -0.0525, -0.0023],\n",
            "         [-0.0406, -0.0527,  0.3837],\n",
            "         [-0.0940,  0.5924,  0.2164],\n",
            "         [ 0.1135,  0.0959, -0.0280],\n",
            "         [ 0.4703,  0.0048, -0.0711]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input_size = 4\n",
        "hidden_size = 3\n",
        "batch_size = 2\n",
        "seq_len = 5\n",
        "\n",
        "# Khởi tạo parameters\n",
        "params = init_lstm_parameters(input_size, hidden_size)\n",
        "\n",
        "# Tạo input sequence\n",
        "input_sequence = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "print(\"Input shape:\", input_sequence.shape)\n",
        "\n",
        "# Forward pass\n",
        "output, final_h, final_c = lstm_forward(input_sequence, params, batch_first=True)\n",
        "\n",
        "print(\"\\nOutput shape:\", output.shape)\n",
        "print(\"Final hidden state shape:\", final_h.shape)\n",
        "print(\"Final cell state shape:\", final_c.shape)\n",
        "print(\"\\nOutput:\")\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. So sánh với PyTorch LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our LSTM output shape: torch.Size([2, 5, 3])\n",
            "PyTorch LSTM output shape: torch.Size([2, 5, 3])\n",
            "\n",
            "Output shapes match: True\n",
            "Hidden state shapes match: True\n",
            "Cell state shapes match: True\n"
          ]
        }
      ],
      "source": [
        "input_size = 4\n",
        "hidden_size = 3\n",
        "batch_size = 2\n",
        "seq_len = 5\n",
        "\n",
        "# Our implementation\n",
        "our_params = init_lstm_parameters(input_size, hidden_size)\n",
        "\n",
        "# PyTorch's implementation\n",
        "pytorch_lstm = nn.LSTM(input_size, hidden_size, num_layers=1, batch_first=True)\n",
        "\n",
        "# Same input\n",
        "input_sequence = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "# Forward pass - Our LSTM\n",
        "our_output, our_h, our_c = lstm_forward(input_sequence, our_params, batch_first=True)\n",
        "\n",
        "# Forward pass - PyTorch LSTM\n",
        "pytorch_output, (pytorch_h, pytorch_c) = pytorch_lstm(input_sequence)\n",
        "\n",
        "print(\"Our LSTM output shape:\", our_output.shape)\n",
        "print(\"PyTorch LSTM output shape:\", pytorch_output.shape)\n",
        "print(\"\\nOutput shapes match:\", our_output.shape == pytorch_output.shape)\n",
        "print(\"Hidden state shapes match:\", our_h.shape == pytorch_h.squeeze(0).shape)\n",
        "print(\"Cell state shapes match:\", our_c.shape == pytorch_c.squeeze(0).shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
