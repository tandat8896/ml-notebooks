{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. GRU Cell - Version đơn giản nhất\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gru_cell_forward(input_current, hidden_state_previous,\n",
        "                     weight_ih_r, weight_hh_r, bias_r,\n",
        "                     weight_ih_z, weight_hh_z, bias_z,\n",
        "                     weight_ih_h, weight_hh_h, bias_h):\n",
        "    \"\"\"\n",
        "    Forward pass của GRU cell - Version đơn giản nhất\n",
        "    \n",
        "    Args:\n",
        "        input_current: (batch_size, input_size)\n",
        "        hidden_state_previous: (batch_size, hidden_size)\n",
        "        weight_ih_r, weight_hh_r, bias_r: Parameters cho Reset Gate\n",
        "        weight_ih_z, weight_hh_z, bias_z: Parameters cho Update Gate\n",
        "        weight_ih_h, weight_hh_h, bias_h: Parameters cho Candidate Hidden State\n",
        "    \n",
        "    Returns:\n",
        "        hidden_state_new: (batch_size, hidden_size)\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. RESET GATE: Quyết định reset thông tin nào từ hidden state trước đó\n",
        "    # reset_gate = sigmoid(W_r * x + U_r * h_prev + b_r)\n",
        "    reset_gate = torch.sigmoid(\n",
        "        torch.mm(input_current, weight_ih_r.t()) + \n",
        "        torch.mm(hidden_state_previous, weight_hh_r.t()) + \n",
        "        bias_r\n",
        "    )\n",
        "    \n",
        "    # 2. UPDATE GATE: Quyết định update thông tin mới vào hidden state\n",
        "    # update_gate = sigmoid(W_z * x + U_z * h_prev + b_z)\n",
        "    update_gate = torch.sigmoid(\n",
        "        torch.mm(input_current, weight_ih_z.t()) + \n",
        "        torch.mm(hidden_state_previous, weight_hh_z.t()) + \n",
        "        bias_z\n",
        "    )\n",
        "    \n",
        "    # 3. CANDIDATE HIDDEN STATE: Tạo giá trị candidate cho hidden state mới\n",
        "    # candidate_hidden = tanh(W_h * x + U_h * (reset_gate * h_prev) + b_h)\n",
        "    candidate_hidden = torch.tanh(\n",
        "        torch.mm(input_current, weight_ih_h.t()) + \n",
        "        torch.mm(reset_gate * hidden_state_previous, weight_hh_h.t()) + \n",
        "        bias_h\n",
        "    )\n",
        "    \n",
        "    # 4. CẬP NHẬT HIDDEN STATE\n",
        "    # hidden_state_new = (1 - update_gate) * h_prev + update_gate * candidate_hidden\n",
        "    hidden_state_new = (1 - update_gate) * hidden_state_previous + update_gate * candidate_hidden\n",
        "    \n",
        "    return hidden_state_new\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Khởi tạo Parameters (Đơn giản - không dùng Xavier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_gru_parameters(input_size, hidden_size):\n",
        "    \"\"\"\n",
        "    Khởi tạo parameters cho GRU - Đơn giản nhất\n",
        "    \"\"\"\n",
        "    # Reset Gate parameters\n",
        "    weight_ih_r = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "    weight_hh_r = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "    bias_r = nn.Parameter(torch.zeros(hidden_size))\n",
        "    \n",
        "    # Update Gate parameters\n",
        "    weight_ih_z = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "    weight_hh_z = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "    bias_z = nn.Parameter(torch.zeros(hidden_size))\n",
        "    \n",
        "    # Candidate Hidden State parameters\n",
        "    weight_ih_h = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "    weight_hh_h = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "    bias_h = nn.Parameter(torch.zeros(hidden_size))\n",
        "    \n",
        "    return {\n",
        "        'weight_ih_r': weight_ih_r, 'weight_hh_r': weight_hh_r, 'bias_r': bias_r,\n",
        "        'weight_ih_z': weight_ih_z, 'weight_hh_z': weight_hh_z, 'bias_z': bias_z,\n",
        "        'weight_ih_h': weight_ih_h, 'weight_hh_h': weight_hh_h, 'bias_h': bias_h\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test GRU Cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Initial hidden state shape: torch.Size([2, 3])\n",
            "\n",
            "After forward pass:\n",
            "New hidden state shape: torch.Size([2, 3])\n",
            "\n",
            "New hidden state:\n",
            "tensor([[-0.6203, -0.0158,  0.0007],\n",
            "        [-0.6222, -0.0956,  0.0054]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input_size = 4\n",
        "hidden_size = 3\n",
        "batch_size = 2\n",
        "\n",
        "# Khởi tạo parameters\n",
        "params = init_gru_parameters(input_size, hidden_size)\n",
        "\n",
        "# Tạo input và initial state\n",
        "input_current = torch.randn(batch_size, input_size)\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "print(\"Input shape:\", input_current.shape)\n",
        "print(\"Initial hidden state shape:\", h_prev.shape)\n",
        "\n",
        "# Forward pass\n",
        "h_new = gru_cell_forward(\n",
        "    input_current, h_prev,\n",
        "    params['weight_ih_r'], params['weight_hh_r'], params['bias_r'],\n",
        "    params['weight_ih_z'], params['weight_hh_z'], params['bias_z'],\n",
        "    params['weight_ih_h'], params['weight_hh_h'], params['bias_h']\n",
        ")\n",
        "\n",
        "print(\"\\nAfter forward pass:\")\n",
        "print(\"New hidden state shape:\", h_new.shape)\n",
        "print(\"\\nNew hidden state:\")\n",
        "print(h_new)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gru_forward(input_sequence, params, batch_first=True):\n",
        "    \"\"\"\n",
        "    Forward pass qua GRU layer cho sequence\n",
        "    \n",
        "    Args:\n",
        "        input_sequence: (batch_size, seq_len, input_size) nếu batch_first=True\n",
        "                       (seq_len, batch_size, input_size) nếu batch_first=False\n",
        "        params: Dictionary chứa tất cả parameters\n",
        "        batch_first: True nếu input là (batch, seq, features)\n",
        "    \n",
        "    Returns:\n",
        "        output: (batch_size, seq_len, hidden_size) nếu batch_first=True\n",
        "                (seq_len, batch_size, hidden_size) nếu batch_first=False\n",
        "        final_hidden_state: (batch_size, hidden_size)\n",
        "    \"\"\"\n",
        "    if batch_first:\n",
        "        batch_size, seq_len, input_size = input_sequence.shape\n",
        "    else:\n",
        "        seq_len, batch_size, input_size = input_sequence.shape\n",
        "    \n",
        "    hidden_size = params['weight_ih_r'].shape[0]\n",
        "    \n",
        "    # Khởi tạo hidden state\n",
        "    h = torch.zeros(batch_size, hidden_size, device=input_sequence.device, dtype=input_sequence.dtype)\n",
        "    \n",
        "    outputs = []\n",
        "    \n",
        "    # Xử lý từng time step\n",
        "    for t in range(seq_len):\n",
        "        # Lấy input tại time step t\n",
        "        if batch_first:\n",
        "            x_t = input_sequence[:, t, :]  # (batch_size, input_size)\n",
        "        else:\n",
        "            x_t = input_sequence[t]  # (batch_size, input_size)\n",
        "        \n",
        "        # Forward qua GRU cell\n",
        "        h = gru_cell_forward(\n",
        "            x_t, h,\n",
        "            params['weight_ih_r'], params['weight_hh_r'], params['bias_r'],\n",
        "            params['weight_ih_z'], params['weight_hh_z'], params['bias_z'],\n",
        "            params['weight_ih_h'], params['weight_hh_h'], params['bias_h']\n",
        "        )\n",
        "        \n",
        "        # Lưu output\n",
        "        outputs.append(h)\n",
        "    \n",
        "    # Stack outputs\n",
        "    if batch_first:\n",
        "        output = torch.stack(outputs, dim=1)  # (batch_size, seq_len, hidden_size)\n",
        "    else:\n",
        "        output = torch.stack(outputs, dim=0)  # (seq_len, batch_size, hidden_size)\n",
        "    \n",
        "    return output, h\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test GRU Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 5, 4])\n",
            "\n",
            "Output shape: torch.Size([2, 5, 3])\n",
            "Final hidden state shape: torch.Size([2, 3])\n",
            "\n",
            "Output:\n",
            "tensor([[[-0.1132, -0.0307,  0.8701],\n",
            "         [-0.6443, -0.2697,  0.5332],\n",
            "         [-0.7137, -0.2707,  0.6518],\n",
            "         [-0.7024, -0.2293,  0.7325],\n",
            "         [-0.3107, -0.2297,  0.9162]],\n",
            "\n",
            "        [[ 0.1312, -0.1023,  0.2817],\n",
            "         [ 0.8074, -0.1091,  0.0809],\n",
            "         [ 0.4824,  0.5362,  0.3975],\n",
            "         [ 0.8798,  0.8491,  0.0958],\n",
            "         [ 0.9736,  0.2081, -0.1529]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input_size = 4\n",
        "hidden_size = 3\n",
        "batch_size = 2\n",
        "seq_len = 5\n",
        "\n",
        "# Khởi tạo parameters\n",
        "params = init_gru_parameters(input_size, hidden_size)\n",
        "\n",
        "# Tạo input sequence\n",
        "input_sequence = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "print(\"Input shape:\", input_sequence.shape)\n",
        "\n",
        "# Forward pass\n",
        "output, final_h = gru_forward(input_sequence, params, batch_first=True)\n",
        "\n",
        "print(\"\\nOutput shape:\", output.shape)\n",
        "print(\"Final hidden state shape:\", final_h.shape)\n",
        "print(\"\\nOutput:\")\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. So sánh với PyTorch GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.0485,  0.2012,  0.1549],\n",
            "         [ 0.1199,  0.2688,  0.3696],\n",
            "         [ 0.0655,  0.3771,  0.3831],\n",
            "         [-0.1321,  0.3802,  0.6871],\n",
            "         [ 0.0205,  0.3498,  0.7068]],\n",
            "\n",
            "        [[-0.2097,  0.0193, -0.4212],\n",
            "         [-0.0569,  0.0637, -0.5055],\n",
            "         [ 0.0231,  0.1297,  0.0946],\n",
            "         [-0.0409,  0.1225,  0.0962],\n",
            "         [-0.3406,  0.1711, -0.1552]]], grad_fn=<TransposeBackward1>) tensor([[[ 0.0205,  0.3498,  0.7068],\n",
            "         [-0.3406,  0.1711, -0.1552]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input_size = 4\n",
        "hidden_size = 3\n",
        "batch_size = 2\n",
        "seq_len = 5\n",
        "\n",
        "# Our implementation\n",
        "our_params = init_gru_parameters(input_size, hidden_size)\n",
        "\n",
        "# PyTorch's implementation\n",
        "pytorch_gru = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True)\n",
        "\n",
        "# Same input\n",
        "input_sequence = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "# Forward pass - Our GRU\n",
        "our_output, our_h = gru_forward(input_sequence, our_params, batch_first=True)\n",
        "\n",
        "# Forward pass - PyTorch GRU\n",
        "pytorch_output, pytorch_h = pytorch_gru(input_sequence)\n",
        "\n",
        "print(pytorch_output, pytorch_h)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
