{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O8CoacHVHWQ",
        "outputId": "13feb115-8dea-4fd8-e61e-bb8cf7852490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch Version 2.9.0+cpu\n",
            "Device cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "print(f\"Pytorch Version {torch.__version__}\")\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self,\n",
        "                 normalized_shape,\n",
        "                 eps=1e-5,\n",
        "                 data_format=\"channels_last\"\n",
        "                  ):\n",
        "      super().__init__()\n",
        "      self.weight= nn.Parameter(torch.ones(normalized_shape))\n",
        "      self.bias= nn.Parameter(torch.ones(normalized_shape))\n",
        "      self.eps= eps\n",
        "      self.data_format= data_format\n",
        "      if self.data_format not in (\"channels_last\",\"channels_first\"):\n",
        "        raise NotImplementedError\n",
        "      self.normalized_shape= (normalized_shape,)\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.data_format==\"channels_last\":\n",
        "        return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
        "      elif self.data_format==\"channels_first\":\n",
        "        u= x.mean(dim=1, keepdim=True)\n",
        "        s= (x-u).pow(2).mean(dim=1, keepdim=True)\n",
        "        x= (x-u)/ torch.sqrt(s+self.eps)\n",
        "        x= self.weight[:, None, None] * x + self.bias[:, None, None]\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "DBd7QzzcVj9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DropPath(nn.Module):\n",
        "  def __init__(self, drop_prob=0.):\n",
        "    super(DropPath, self).__init__()\n",
        "    self.drop_prob= drop_prob\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.drop_prob ==0 or not self.training:\n",
        "      return x\n",
        "    keep_prob= 1- self.drop_prob\n",
        "    shape= (x.shape[0], ) + (1,) * (x.ndim -1)\n",
        "    random_tensor= keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor_()\n",
        "    output= x.div(keep_prob) * random_tensor\n",
        "    return output"
      ],
      "metadata": {
        "id": "p4cWKFNUWkYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalResponeNorm(nn.Module):\n",
        "  def __init__(self, dim):\n",
        "    super().__init__()\n",
        "    self.gamma= nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
        "    self.beta= nn.Parameter(torch.zeros(1,1,1, dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    Global_x= torch.norm(x, p=2, dim=(1,2), keepdim=True)\n",
        "    Norm_x= Global_x / (Global_x.mean(dim=-1, keepdim=True) + 1e-6)\n",
        "    return self.gamma * (x * Norm_x) + self.beta\n",
        "print(\"GRN (Global Response Normalization) defined successfully!\")\n",
        "print(\"This is the key innovation in ConvNeXt V2!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgBjv8xMXGbp",
        "outputId": "641ce964-c36d-4d9d-a629-5cb0ecbc39a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRN (Global Response Normalization) defined successfully!\n",
            "This is the key innovation in ConvNeXt V2!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" ConvNeXtV2 Block.\n",
        "\n",
        "    Main differences from V1:\n",
        "    - Removed Layer Scale (gamma parameter)\n",
        "    - Added GRN (Global Response Normalization) after GELU\n",
        "\n",
        "    Architecture:\n",
        "        DwConv 7x7 -> Permute -> LayerNorm -> Linear (4x expansion) ->\n",
        "        GELU -> GRN -> Linear (compression) -> Permute -> DropPath -> Residual\n",
        "\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, drop_path=0.):\n",
        "        super().__init__()\n",
        "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
        "        self.norm = LayerNorm(dim, eps=1e-6)\n",
        "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
        "        self.act = nn.GELU()\n",
        "        self.grn= GlobalResponeNorm(dim= 4*dim)\n",
        "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "      input = x\n",
        "      x= self.dwconv(x)\n",
        "      x= x.permute(0,2,3,1)\n",
        "      x= self.norm(x)\n",
        "      x= self.pwconv1(x)\n",
        "      x= self.act(x)\n",
        "      x= self.grn(x)\n",
        "      x= self.pwconv2(x)\n",
        "      x= x.permute(0,3,1,2)\n",
        "      x= self.drop_path(x)\n",
        "      x= x+input\n",
        "      return x\n",
        "\n",
        "print(\"ConvNeXt V2 Block defined successfully!\")\n",
        "print(\"Note: This uses GRN instead of Layer Scale from V1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BuwkOCoYIPY",
        "outputId": "d6771c11-ca07-494b-8bf3-6c2474815f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNeXt V2 Block defined successfully!\n",
            "Note: This uses GRN instead of Layer Scale from V1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNeXtV2(nn.Module):\n",
        "    \"\"\" ConvNeXt V2\n",
        "        A PyTorch impl of : `ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders`\n",
        "        http://arxiv.org/abs/2301.00808\n",
        "\n",
        "    Args:\n",
        "        in_chans (int): Number of input image channels. Default: 3\n",
        "        num_classes (int): Number of classes for classification head. Default: 1000\n",
        "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
        "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
        "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
        "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 in_channels=3,\n",
        "                 num_classes=1000,\n",
        "                 depths=[3, 3, 9, 3],\n",
        "                 dims=[80, 160, 320, 640], # Corrected for Nano model as per the original problem context\n",
        "                 drop_path_rate=0.,\n",
        "                 head_init_scale=1.,\n",
        "                 ):\n",
        "      super().__init__()\n",
        "      self.depths= depths\n",
        "\n",
        "      # Initialize two ModuleLists: one for downsampling ops, one for block stages\n",
        "      self.downsample_layers = nn.ModuleList() # This will hold inter-stage downsampling layers\n",
        "      self.stages = nn.ModuleList()           # This will hold the sequences of Blocks\n",
        "\n",
        "      dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
        "      cur=0\n",
        "\n",
        "      # The stem is a separate module\n",
        "      self.stem = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=in_channels, out_channels= dims[0], kernel_size=4, stride=4),\n",
        "          LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
        "      )\n",
        "\n",
        "      for i in range(len(depths)): # Iterate over the number of stages (0, 1, 2, 3)\n",
        "          # Add the blocks for the current stage to self.stages\n",
        "          blocks = [Block(dim=dims[i], drop_path=dp_rates[cur + j]) for j in range(depths[i])]\n",
        "          self.stages.append(nn.Sequential(*blocks)) # Corresponds to stages.0, stages.1, stages.2, stages.3 in checkpoint\n",
        "          cur += depths[i]\n",
        "\n",
        "          # Add inter-stage downsampling layer for all but the last stage\n",
        "          if i < len(depths) - 1:\n",
        "              downsample_layer = nn.Sequential(\n",
        "                  LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"), # dims[i] is input for next stage\n",
        "                  nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2)\n",
        "              )\n",
        "              # These are downsample_layers[0], downsample_layers[1], downsample_layers[2]\n",
        "              self.downsample_layers.append(downsample_layer)\n",
        "\n",
        "      self.norm= nn.LayerNorm(dims[-1], eps=1e-6)\n",
        "      self.head= nn.Linear(dims[-1], num_classes)\n",
        "\n",
        "      self.apply(self._init_weights)\n",
        "      self.head.weight.data.mul_(head_init_scale)\n",
        "      self.head.bias.data.mul_(head_init_scale)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.trunc_normal_(m.weight, std=.02)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        x = self.stem(x) # Process the initial stem\n",
        "\n",
        "        # Iterate through stages and apply inter-stage downsampling\n",
        "        for i in range(len(self.depths)):\n",
        "            x = self.stages[i](x) # Process blocks for current stage\n",
        "            if i < len(self.depths) - 1: # Apply downsampling for all but the last stage\n",
        "                # Use downsample_layers[i] for downsampling after stages[i]\n",
        "                x = self.downsample_layers[i](x)\n",
        "\n",
        "        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "print(\"ConvNeXt V2 Model defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y28YshN8aFKM",
        "outputId": "b213f7aa-fcdc-4d06-c0f4-a5a835a2cd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNeXt V2 Model defined successfully!\n"
          ]
        }
      ]
    }
  ]
}